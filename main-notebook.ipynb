{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys; sys.path.append(os.getcwd()+'/src')\n",
    "from importlib import reload\n",
    "import class_handler_v2 as classes; reload(classes)\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "x, y = load_breast_cancer(return_X_y=True)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (455,) (114, 30) (114,)\n"
     ]
    }
   ],
   "source": [
    "# Lets split into train and test\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load using new API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metod: 'complete'\n",
      "Initialized classifiers:\n",
      "\tAdaBoost\n",
      "\tKNearestNeighbors\n",
      "\tLogReg\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "import class_handler_v2 as classes; reload(classes)\n",
    "clfs = classes.Classifiers(verbose=1, method='complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier AdaBoost trained (time: 0.00 min)\n",
      "Classifier KNearestNeighbors trained (time: 0.00 min)\n",
      "Classifier LogReg trained (time: 0.00 min)\n"
     ]
    }
   ],
   "source": [
    "clfs.fit_classifiers(X_train, y_train, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = clfs.predict_classifiers(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores:\n",
      "log_loss: 0.0000 \t accuracy: 1.0000 \t AdaBoost\n",
      "log_loss: 1.4423 \t accuracy: 0.9582 \t LogReg\n",
      "log_loss: 2.0496 \t accuracy: 0.9407 \t KNearestNeighbors\n",
      "Test scores:\n",
      "log_loss: 1.5149 \t accuracy: 0.9561 \t KNearestNeighbors\n",
      "log_loss: 1.5149 \t accuracy: 0.9561 \t LogReg\n",
      "log_loss: 2.7268 \t accuracy: 0.9211 \t AdaBoost\n"
     ]
    }
   ],
   "source": [
    "# Evaulate performance on training data\n",
    "print(\"Training scores:\")\n",
    "train_scores = clfs.classifier_performance(y_train_pred, y_train, metric='accuracy')\n",
    "# Evaluate overfitting\n",
    "print(\"Test scores:\")\n",
    "test_scores = clfs.classifier_performance(clfs.predict_classifiers(X_test), y_test, metric='accuracy')\n",
    "# AdaBoost clearly overfits this dataset while LogiReg and KNN seem ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyEAAAFzCAYAAAApNwYmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncjL6uwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x149d12b0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import visualize; reload(visualize)\n",
    "from visualize import Visualizer as viz;\n",
    "# This method expects a list of 2-tuples\n",
    "viz().show_performance([tuple([x,y]) for x,y,_ in train_scores], fig_size=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metod: 'complete'\n",
      "Best mean score: 0.9604 (AdaBoost)\n",
      "Best mean score: 0.9231 (KNearestNeighbors)\n",
      "Best mean score: 0.9538 (LogReg)\n",
      "\n",
      "AdaBoost 1.0\n",
      "AdaBoost 0.947368421053\n",
      "\n",
      "KNearestNeighbors 0.927472527473\n",
      "KNearestNeighbors 0.964912280702\n",
      "\n",
      "LogReg 0.964835164835\n",
      "LogReg 0.964912280702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "# Import classifiers\n",
    "import class_handler_v2 as classes; reload(classes)\n",
    "clfs = classes.Classifiers(verbose=0, method='complete')\n",
    "clfs.verbose = 0\n",
    "optims = clfs.optimize_classifiers(X_train, y_train, n_iter=4, n_jobs=-1)\n",
    "print()\n",
    "for name, clf in optims:\n",
    "    #clf.fit(X_train, y_train)\n",
    "    print(name, accuracy_score(clf.predict(X_train), y_train))\n",
    "    print(name, accuracy_score(clf.predict(X_test), y_test)) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base class for algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import adaboost; reload(adaboost)\n",
    "from adaboost import MetaAdaBoostClassifierAlgorithm\n",
    "ada = MetaAdaBoostClassifierAlgorithm(random_state=0, base_estimator='logreg')\n",
    "print(ada.get_info())\n",
    "ada.cv_param_dist = ada._param_dist_dict()\n",
    "print(ada.cv_param_dist)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist = ada.cv_param_dist\n",
    "estimator = ada.estimator\n",
    "\n",
    "# IT SEEMS THAT THE LOGISTIC REGRESSION CLASSIFIER TENDS TO OVERFIT...SHOULD LOWER n_iter IF USING THAT ALGO.\n",
    "grid_search = RandomizedSearchCV(estimator, param_distributions=param_dist, n_iter=1, scoring='neg_log_loss',\n",
    "                       cv=10, n_jobs=-1, verbose=0, error_score=0, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best mean score: %.4f\" % (grid_search.best_score_))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy on test set: %.4f\" % accuracy_score(y_test, grid_search.best_estimator_.predict(X_test))) \n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with nearest neighbors algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nearest_neighbors; reload(nearest_neighbors)\n",
    "from nearest_neighbors import MetaKNearestNeighborClassifierAlgorithm\n",
    "knn = MetaKNearestNeighborClassifierAlgorithm()\n",
    "print(knn.get_info())\n",
    "knn.cv_param_dist = knn._param_dist_dict()\n",
    "print(type(knn.cv_param_dist))\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "param_dist = knn.cv_param_dist\n",
    "estimator = knn.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(param_dist.param_grid)\n",
    "print(\"number of grids = %i\" % len(param_dist.param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for grid in param_dist.param_grid:\n",
    "    grid_search = RandomizedSearchCV(estimator, param_distributions=grid, n_iter=2, scoring='accuracy',\n",
    "                           cv=10, n_jobs=-1, verbose=0, error_score=0, return_train_score=True)\n",
    "    #grid_search = GridSearchCV(estimator, param_grid=param_dist.param_grid, scoring='accuracy',\n",
    "    #                       cv=10, n_jobs=-1, verbose=0, error_score=0, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best mean score: %.4f\" % (grid_search.best_score_))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(\"Accuracy on test set: %.4f\" % accuracy_score(y_test, grid_search.best_estimator_.predict(X_test))) \n",
    "    results.append((grid_search.best_score_, grid_search.best_estimator_))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import classifiers\n",
    "clfs = classes.Classifiers(verbose=0, method='complete', num_clf=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting and tuning of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way of optimizing the hyper parameters of each selected algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular fitting (just train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic building block: \"fit_classifiers\" loops over each algorithm and trains on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit classifiers on data\n",
    "clfs.fit_classifiers(X_train,y_train,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyper parameters using cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring options:\n",
    "* ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_median_absolute_error', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete and categorical variables (using scipy.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "scorer = make_scorer(log_loss, greater_is_better=False)\n",
    "scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neg_log_loss(y_true, y_pred):\n",
    "    return -1.0 * log_loss(y_true, y_pred)\n",
    "scorer = make_scorer(neg_log_loss)\n",
    "scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [1, 2, 3, 8, 12, None],\n",
    "              \"max_features\": sp_randint(2, 15),\n",
    "              \"min_samples_split\": sp_randint(2, 15),\n",
    "              \"min_samples_leaf\": sp_randint(2, 15),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"n_estimators\": [10, 100, 500]} \n",
    "estimator = RandomForestClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator, param_distributions=param_dist, n_iter=10, scoring=scorer,\n",
    "                       cv=10, n_jobs=-1, verbose=0, error_score=0, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "#pd.DataFrame(grid_search.cv_results_).head()\n",
    "print(\"Best mean score: %.4f\" % (grid_search.best_score_))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy on test set: %.4f\" % accuracy_score(y_test, grid_search.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous variable (using scipy.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, gamma, lognorm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_dist = {\"C\": uniform(loc=0., scale=200.),\n",
    "              \"fit_intercept\": [True, False],\n",
    "              \"penalty\": ['l1', 'l2'],\n",
    "              \"max_iter\": [50, 100, 150]}\n",
    "estimator = LogisticRegression()\n",
    "grid_search = RandomizedSearchCV(estimator, param_distributions=param_dist, n_iter=200, scoring='accuracy',\n",
    "                       cv=10, n_jobs=-1, verbose=0, error_score=0, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best mean score: %.4f\" % (grid_search.best_score_))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict on data (returns a list of (name, prediction) tuples for each classifier in repository)\n",
    "preds = clfs.predict_classifiers(X_train)\n",
    "clfs.verbose = 1 # Report progress if =1, else be quiet if =0.\n",
    "# How well are we doing?\n",
    "scores = clfs.classifier_performance(preds, y_train, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = clfs.predict_classifiers(X_test)\n",
    "clfs.verbose = 1 # Report progress if =1, else be quiet if =0.\n",
    "# How well are we doing?\n",
    "scores = clfs.classifier_performance(preds, y_test, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an instance \"correlation checking\" classes\n",
    "import class_handler as classes; reload(classes)\n",
    "check = classes.CheckClassifierCorrelation(prediction_type='c_binary')\n",
    "# Get names and correlation matrix\n",
    "names_, corr_ = check.compute_correlation_matrix(preds)\n",
    "# Plot correlation matrix (output depends on if plotting inline or not)\n",
    "fig = check.plot_correlation_matrix(names_, corr_, fig_size=(16,10), rot=20, font_scale=1.1, file=os.getcwd()+\"/corr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [datascience]",
   "language": "python",
   "name": "Python [datascience]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
