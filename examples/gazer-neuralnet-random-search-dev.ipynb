{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/magnusax/AutoML/gazer/__init__.py:16: RuntimeWarning: xgboost import failed; 'xgboost' \n",
      "        will be unavailable.\n",
      "  will be unavailable.\"\"\".format(lib, alias), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.insert(0, \"/Users/magnusax/AutoML\")\n",
    "from gazer import GazerMetaLearner\n",
    "from gazer.optimization import param_search\n",
    "from sklearn.datasets import load_digits\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.5, random_state=0)\n",
    "#y_train = to_categorical(y_train)\n",
    "#y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learner = GazerMetaLearner(\n",
    "    method='select', \n",
    "    estimators=['neuralnet'], \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'epochs': randint(5, 31),\n",
    "    'input_units': randint(200, 1201),\n",
    "    'dropout': [True, False],\n",
    "    'p': uniform(0,0.7),\n",
    "    'batch_size': randint(16, 129),\n",
    "    'batch_norm': [False, True],\n",
    "    'n_hidden': randint(2,4),   \n",
    "    'decay_units': [True, False],\n",
    "    'learning_rate': [1e-3 * x for x in range(1, 11)],\n",
    "    'optimizer': ['adam', 'adagrad'],\n",
    "    'gamma': uniform(1.5, 1.0),\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'train': (X_train, y_train), \n",
    "    'val': (X_test, y_test)\n",
    "}\n",
    "\n",
    "type_of_search = 'random'\n",
    "\n",
    "n_iter = 100\n",
    "\n",
    "name = learner.names[0]\n",
    "\n",
    "modelfiles = [\"tmp/model{}.hdf5\".format(i) for i in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a705e2bdbc7479d88c59c850d61956f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config, df = param_search(learner, param_grid, data, \n",
    "                          type_of_search=type_of_search, \n",
    "                          n_iter=n_iter, name=name, \n",
    "                          modelfiles=modelfiles, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_norm</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>decay_units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>gamma</th>\n",
       "      <th>input_units</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_hidden</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>p</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>True</td>\n",
       "      <td>92</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>2.164772</td>\n",
       "      <td>718</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.199357</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>2.157223</td>\n",
       "      <td>761</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.406312</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>True</td>\n",
       "      <td>115</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>2.451649</td>\n",
       "      <td>892</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.265402</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>1.982446</td>\n",
       "      <td>671</td>\n",
       "      <td>0.009</td>\n",
       "      <td>3</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.666452</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>1.617226</td>\n",
       "      <td>359</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.277546</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>92</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>1.670565</td>\n",
       "      <td>936</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.346420</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>True</td>\n",
       "      <td>86</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>2.440254</td>\n",
       "      <td>452</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.052628</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>True</td>\n",
       "      <td>83</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>2.445365</td>\n",
       "      <td>305</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.691845</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>1.970324</td>\n",
       "      <td>646</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.400966</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>2.372189</td>\n",
       "      <td>827</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.237888</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>True</td>\n",
       "      <td>93</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>552</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.689255</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>False</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>1.515386</td>\n",
       "      <td>266</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.218241</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>1.655869</td>\n",
       "      <td>1167</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.457649</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>1.912526</td>\n",
       "      <td>568</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.074532</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>False</td>\n",
       "      <td>125</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>1.685536</td>\n",
       "      <td>453</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.138185</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>107</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>1.896324</td>\n",
       "      <td>819</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.634315</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>0.9789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>True</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>1.920328</td>\n",
       "      <td>584</td>\n",
       "      <td>0.009</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.053240</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>False</td>\n",
       "      <td>67</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "      <td>2.081769</td>\n",
       "      <td>1119</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.029261</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>101</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>1.673758</td>\n",
       "      <td>271</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.636489</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>True</td>\n",
       "      <td>107</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>1.616126</td>\n",
       "      <td>773</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.163225</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>71</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>2.441546</td>\n",
       "      <td>1156</td>\n",
       "      <td>0.004</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.408861</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>True</td>\n",
       "      <td>126</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>1.834490</td>\n",
       "      <td>932</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.010813</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>False</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>1.880408</td>\n",
       "      <td>882</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.298583</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>False</td>\n",
       "      <td>115</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>2.127296</td>\n",
       "      <td>776</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.525248</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.9766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>1.576127</td>\n",
       "      <td>304</td>\n",
       "      <td>0.007</td>\n",
       "      <td>3</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.145355</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>True</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>1.586635</td>\n",
       "      <td>584</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.319783</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>True</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>1.769392</td>\n",
       "      <td>707</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.308908</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>1.706127</td>\n",
       "      <td>1022</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.063555</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>False</td>\n",
       "      <td>102</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>1.751615</td>\n",
       "      <td>359</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.525131</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "      <td>1.504867</td>\n",
       "      <td>620</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.044342</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>True</td>\n",
       "      <td>81</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>1.750174</td>\n",
       "      <td>234</td>\n",
       "      <td>0.006</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.036993</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>True</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "      <td>1.520706</td>\n",
       "      <td>360</td>\n",
       "      <td>0.008</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.058633</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.9566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2.312634</td>\n",
       "      <td>406</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.518446</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.1513</td>\n",
       "      <td>0.9878</td>\n",
       "      <td>0.9544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>False</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>2.474577</td>\n",
       "      <td>250</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.640502</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>0.9511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>True</td>\n",
       "      <td>107</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>1.574681</td>\n",
       "      <td>477</td>\n",
       "      <td>0.009</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.157113</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.9878</td>\n",
       "      <td>0.9477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>124</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>2.137996</td>\n",
       "      <td>1141</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.361793</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.9878</td>\n",
       "      <td>0.9477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>2.018783</td>\n",
       "      <td>478</td>\n",
       "      <td>0.007</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.150018</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.9399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>False</td>\n",
       "      <td>92</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "      <td>2.271539</td>\n",
       "      <td>218</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.216845</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>0.9777</td>\n",
       "      <td>0.9388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>True</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>1.802877</td>\n",
       "      <td>424</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.258735</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.9155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>False</td>\n",
       "      <td>97</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>2.470406</td>\n",
       "      <td>829</td>\n",
       "      <td>0.002</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.475919</td>\n",
       "      <td>0.4155</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>0.8799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>True</td>\n",
       "      <td>100</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "      <td>2.236906</td>\n",
       "      <td>655</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.377263</td>\n",
       "      <td>0.3788</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.8754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>2.353056</td>\n",
       "      <td>407</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.582093</td>\n",
       "      <td>0.3525</td>\n",
       "      <td>0.7134</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>0.8699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>2.387656</td>\n",
       "      <td>1068</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.602475</td>\n",
       "      <td>2.0612</td>\n",
       "      <td>2.0848</td>\n",
       "      <td>0.5568</td>\n",
       "      <td>0.5117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>False</td>\n",
       "      <td>50</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>1.826826</td>\n",
       "      <td>835</td>\n",
       "      <td>0.002</td>\n",
       "      <td>3</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.679326</td>\n",
       "      <td>2.2397</td>\n",
       "      <td>2.2459</td>\n",
       "      <td>0.3853</td>\n",
       "      <td>0.3660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>114</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>2.294137</td>\n",
       "      <td>598</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.451073</td>\n",
       "      <td>13.1386</td>\n",
       "      <td>12.5704</td>\n",
       "      <td>0.1849</td>\n",
       "      <td>0.2191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>False</td>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>1.794173</td>\n",
       "      <td>499</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.146728</td>\n",
       "      <td>12.8693</td>\n",
       "      <td>12.9088</td>\n",
       "      <td>0.2016</td>\n",
       "      <td>0.1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>False</td>\n",
       "      <td>48</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>2.035419</td>\n",
       "      <td>723</td>\n",
       "      <td>0.008</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.312689</td>\n",
       "      <td>14.5027</td>\n",
       "      <td>14.4507</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>False</td>\n",
       "      <td>92</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>1.581434</td>\n",
       "      <td>1108</td>\n",
       "      <td>0.009</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.444805</td>\n",
       "      <td>14.5924</td>\n",
       "      <td>14.4686</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>False</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>1.555037</td>\n",
       "      <td>468</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.092374</td>\n",
       "      <td>14.6463</td>\n",
       "      <td>14.4686</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>False</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>1.705495</td>\n",
       "      <td>921</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.487813</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>14.4686</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>2.245408</td>\n",
       "      <td>686</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>14.4686</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>False</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>1.524129</td>\n",
       "      <td>1089</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.221097</td>\n",
       "      <td>14.6463</td>\n",
       "      <td>14.4686</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>False</td>\n",
       "      <td>63</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>1.950359</td>\n",
       "      <td>469</td>\n",
       "      <td>0.010</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.166119</td>\n",
       "      <td>14.4668</td>\n",
       "      <td>14.5045</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>2.011719</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.007</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.276951</td>\n",
       "      <td>14.4668</td>\n",
       "      <td>14.5224</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>67</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>2.324231</td>\n",
       "      <td>1093</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.305027</td>\n",
       "      <td>14.5206</td>\n",
       "      <td>14.5224</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>False</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>1.846793</td>\n",
       "      <td>965</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.235114</td>\n",
       "      <td>14.4668</td>\n",
       "      <td>14.5224</td>\n",
       "      <td>0.1024</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>1.600724</td>\n",
       "      <td>949</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.405949</td>\n",
       "      <td>14.5206</td>\n",
       "      <td>14.5224</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>False</td>\n",
       "      <td>126</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>2.369172</td>\n",
       "      <td>440</td>\n",
       "      <td>0.009</td>\n",
       "      <td>3</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.630923</td>\n",
       "      <td>2.2994</td>\n",
       "      <td>2.3102</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>False</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>2.299105</td>\n",
       "      <td>1082</td>\n",
       "      <td>0.008</td>\n",
       "      <td>2</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.243700</td>\n",
       "      <td>14.3053</td>\n",
       "      <td>14.7196</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>102</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "      <td>1.749254</td>\n",
       "      <td>1170</td>\n",
       "      <td>0.008</td>\n",
       "      <td>3</td>\n",
       "      <td>adagrad</td>\n",
       "      <td>0.472058</td>\n",
       "      <td>14.2335</td>\n",
       "      <td>14.7555</td>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.0845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_norm  batch_size  decay_units  dropout  epochs     gamma  \\\n",
       "32        True          92         True    False      25  2.164772   \n",
       "20        True          50        False     True       9  2.157223   \n",
       "31        True         115         True    False      28  2.451649   \n",
       "7         True          65        False    False      14  1.982446   \n",
       "45        True          39        False     True      18  1.617226   \n",
       "5         True          92         True     True      25  1.670565   \n",
       "72        True          86         True    False      24  2.440254   \n",
       "61        True          83        False    False      20  2.445365   \n",
       "88       False          22         True    False      30  1.970324   \n",
       "38        True          40        False     True      30  2.372189   \n",
       "89        True          93         True    False      16  1.802900   \n",
       "86       False          58        False    False      24  1.515386   \n",
       "19        True          49         True    False      10  1.655869   \n",
       "87        True          34        False    False      16  1.912526   \n",
       "23       False         125         True    False      15  1.685536   \n",
       "11        True         107        False     True      13  1.896324   \n",
       "36        True          51        False    False      14  1.920328   \n",
       "41       False          67        False     True      28  2.081769   \n",
       "6         True         101         True    False      25  1.673758   \n",
       "66        True         107         True    False      19  1.616126   \n",
       "8        False          71         True    False      22  2.441546   \n",
       "52        True         126         True    False      21  1.834490   \n",
       "27       False         101        False    False      15  1.880408   \n",
       "33       False         115        False     True      13  2.127296   \n",
       "34        True          19         True    False      11  1.576127   \n",
       "44        True          61        False    False      13  1.586635   \n",
       "97        True          56        False    False      22  1.769392   \n",
       "80       False          47         True    False      21  1.706127   \n",
       "78       False         102         True    False      26  1.751615   \n",
       "58       False         128        False     True      21  1.504867   \n",
       "..         ...         ...          ...      ...     ...       ...   \n",
       "83        True          81        False     True      22  1.750174   \n",
       "64        True          95        False     True      29  1.520706   \n",
       "53       False          23         True    False       8  2.312634   \n",
       "62       False         100         True    False      14  2.474577   \n",
       "29        True         107         True     True       9  1.574681   \n",
       "15        True         124        False     True      23  2.137996   \n",
       "39        True          27         True    False      25  2.018783   \n",
       "73       False          92         True     True      29  2.271539   \n",
       "71        True          73        False    False       7  1.802877   \n",
       "26       False          97         True     True       9  2.470406   \n",
       "90        True         100         True     True      14  2.236906   \n",
       "76        True          25        False    False      22  2.353056   \n",
       "54       False          36         True     True       6  2.387656   \n",
       "21       False          50         True     True      19  1.826826   \n",
       "16       False         114         True    False      13  2.294137   \n",
       "25       False          66        False     True       6  1.794173   \n",
       "50       False          48        False    False      30  2.035419   \n",
       "18       False          92         True     True      24  1.581434   \n",
       "70       False          70        False    False      12  1.555037   \n",
       "79       False          46        False    False      21  1.705495   \n",
       "63       False          29        False     True      12  2.245408   \n",
       "92       False          58        False    False      30  1.524129   \n",
       "37       False          63        False     True      13  1.950359   \n",
       "69       False          36         True    False      28  2.011719   \n",
       "49       False          67        False    False      24  2.324231   \n",
       "57       False          98        False    False      19  1.846793   \n",
       "84       False          44         True     True      19  1.600724   \n",
       "35       False         126         True     True       9  2.369172   \n",
       "85       False          61        False    False      22  2.299105   \n",
       "12       False         102        False     True      29  1.749254   \n",
       "\n",
       "    input_units  learning_rate  n_hidden optimizer         p  train_loss  \\\n",
       "32          718          0.003         3      adam  0.199357      0.0004   \n",
       "20          761          0.007         2   adagrad  0.406312      0.0008   \n",
       "31          892          0.003         3      adam  0.265402      0.0005   \n",
       "7           671          0.009         3   adagrad  0.666452      0.0005   \n",
       "45          359          0.005         3   adagrad  0.277546      0.0003   \n",
       "5           936          0.005         3      adam  0.346420      0.0018   \n",
       "72          452          0.003         2      adam  0.052628      0.0005   \n",
       "61          305          0.001         2      adam  0.691845      0.0006   \n",
       "88          646          0.001         3      adam  0.400966      0.0000   \n",
       "38          827          0.005         2   adagrad  0.237888      0.0000   \n",
       "89          552          0.003         2      adam  0.689255      0.0007   \n",
       "86          266          0.002         2   adagrad  0.218241      0.0062   \n",
       "19         1167          0.003         3   adagrad  0.457649      0.0008   \n",
       "87          568          0.001         3      adam  0.074532      0.0002   \n",
       "23          453          0.007         2   adagrad  0.138185      0.0039   \n",
       "11          819          0.004         2   adagrad  0.634315      0.0152   \n",
       "36          584          0.009         2   adagrad  0.053240      0.0003   \n",
       "41         1119          0.002         3      adam  0.029261      0.0000   \n",
       "6           271          0.004         2      adam  0.636489      0.0004   \n",
       "66          773          0.001         3      adam  0.163225      0.0003   \n",
       "8          1156          0.004         2   adagrad  0.408861      0.0014   \n",
       "52          932          0.001         2      adam  0.010813      0.0027   \n",
       "27          882          0.001         3      adam  0.298583      0.0008   \n",
       "33          776          0.006         2   adagrad  0.525248      0.0206   \n",
       "34          304          0.007         3   adagrad  0.145355      0.0058   \n",
       "44          584          0.002         3   adagrad  0.319783      0.0003   \n",
       "97          707          0.001         2      adam  0.308908      0.0010   \n",
       "80         1022          0.002         3      adam  0.063555      0.0000   \n",
       "78          359          0.003         2      adam  0.525131      0.0004   \n",
       "58          620          0.003         2   adagrad  0.044342      0.0015   \n",
       "..          ...            ...       ...       ...       ...         ...   \n",
       "83          234          0.006         3      adam  0.036993      0.0248   \n",
       "64          360          0.008         3      adam  0.058633      0.0092   \n",
       "53          406          0.001         3      adam  0.518446      0.0314   \n",
       "62          250          0.010         3   adagrad  0.640502      0.0509   \n",
       "29          477          0.009         2      adam  0.157113      0.0535   \n",
       "15         1141          0.003         3      adam  0.361793      0.0528   \n",
       "39          478          0.007         3      adam  0.150018      0.0400   \n",
       "73          218          0.003         2   adagrad  0.216845      0.1048   \n",
       "71          424          0.007         2      adam  0.258735      0.1437   \n",
       "26          829          0.002         2   adagrad  0.475919      0.4155   \n",
       "90          655          0.001         3   adagrad  0.377263      0.3788   \n",
       "76          407          0.005         3      adam  0.582093      0.3525   \n",
       "54         1068          0.001         3      adam  0.602475      2.0612   \n",
       "21          835          0.002         3   adagrad  0.679326      2.2397   \n",
       "16          598          0.010         2   adagrad  0.451073     13.1386   \n",
       "25          499          0.010         2   adagrad  0.146728     12.8693   \n",
       "50          723          0.008         3      adam  0.312689     14.5027   \n",
       "18         1108          0.009         2      adam  0.444805     14.5924   \n",
       "70          468          0.010         2      adam  0.092374     14.6463   \n",
       "79          921          0.005         2      adam  0.487813     14.5386   \n",
       "63          686          0.010         3   adagrad  0.011566     14.5386   \n",
       "92         1089          0.010         2   adagrad  0.221097     14.6463   \n",
       "37          469          0.010         3      adam  0.166119     14.4668   \n",
       "69         1025          0.007         2   adagrad  0.276951     14.4668   \n",
       "49         1093          0.006         2      adam  0.305027     14.5206   \n",
       "57          965          0.005         2   adagrad  0.235114     14.4668   \n",
       "84          949          0.010         2   adagrad  0.405949     14.5206   \n",
       "35          440          0.009         3      adam  0.630923      2.2994   \n",
       "85         1082          0.008         2      adam  0.243700     14.3053   \n",
       "12         1170          0.008         3   adagrad  0.472058     14.2335   \n",
       "\n",
       "    val_loss  train_score  val_score  \n",
       "32    0.0531       1.0000     0.9844  \n",
       "20    0.0637       1.0000     0.9833  \n",
       "31    0.0575       1.0000     0.9833  \n",
       "7     0.0662       1.0000     0.9811  \n",
       "45    0.0688       1.0000     0.9811  \n",
       "5     0.0948       0.9989     0.9800  \n",
       "72    0.0623       1.0000     0.9800  \n",
       "61    0.0705       1.0000     0.9800  \n",
       "88    0.1147       1.0000     0.9800  \n",
       "38    0.0858       1.0000     0.9800  \n",
       "89    0.0652       1.0000     0.9800  \n",
       "86    0.0751       1.0000     0.9789  \n",
       "19    0.0625       1.0000     0.9789  \n",
       "87    0.0898       1.0000     0.9789  \n",
       "23    0.0747       1.0000     0.9789  \n",
       "11    0.0792       0.9944     0.9789  \n",
       "36    0.0954       1.0000     0.9778  \n",
       "41    0.1230       1.0000     0.9778  \n",
       "6     0.0600       1.0000     0.9778  \n",
       "66    0.0826       1.0000     0.9778  \n",
       "8     0.0716       1.0000     0.9778  \n",
       "52    0.0769       1.0000     0.9778  \n",
       "27    0.1105       1.0000     0.9766  \n",
       "33    0.1052       0.9978     0.9766  \n",
       "34    0.0795       1.0000     0.9766  \n",
       "44    0.0766       1.0000     0.9766  \n",
       "97    0.0831       1.0000     0.9766  \n",
       "80    0.0978       1.0000     0.9766  \n",
       "78    0.1041       1.0000     0.9766  \n",
       "58    0.0891       1.0000     0.9755  \n",
       "..       ...          ...        ...  \n",
       "83    0.1830       0.9911     0.9588  \n",
       "64    0.2099       0.9989     0.9566  \n",
       "53    0.1513       0.9878     0.9544  \n",
       "62    0.1627       0.9911     0.9511  \n",
       "29    0.2420       0.9878     0.9477  \n",
       "15    0.3778       0.9878     0.9477  \n",
       "39    0.2091       0.9889     0.9399  \n",
       "73    0.1905       0.9777     0.9388  \n",
       "71    0.4429       0.9644     0.9155  \n",
       "26    0.4959       0.9042     0.8799  \n",
       "90    0.4926       0.9265     0.8754  \n",
       "76    0.7134       0.9232     0.8699  \n",
       "54    2.0848       0.5568     0.5117  \n",
       "21    2.2459       0.3853     0.3660  \n",
       "16   12.5704       0.1849     0.2191  \n",
       "25   12.9088       0.2016     0.1991  \n",
       "50   14.4507       0.1002     0.1034  \n",
       "18   14.4686       0.0947     0.1023  \n",
       "70   14.4686       0.0913     0.1023  \n",
       "79   14.4686       0.0980     0.1023  \n",
       "63   14.4686       0.0980     0.1023  \n",
       "92   14.4686       0.0913     0.1023  \n",
       "37   14.5045       0.1024     0.1001  \n",
       "69   14.5224       0.1024     0.0990  \n",
       "49   14.5224       0.0991     0.0990  \n",
       "57   14.5224       0.1024     0.0990  \n",
       "84   14.5224       0.0991     0.0990  \n",
       "35    2.3102       0.1125     0.0868  \n",
       "85   14.7196       0.1125     0.0868  \n",
       "12   14.7555       0.1169     0.0845  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(modelfiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05312484056671752, 0.98442714126807562]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, to_categorical(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_144 (Dense)            (None, 718)               46670     \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 718)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 718)               2872      \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 331)               237989    \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 331)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 331)               1324      \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 153)               50796     \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 153)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 153)               612       \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 70)                10780     \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 10)                710       \n",
      "=================================================================\n",
      "Total params: 352,033\n",
      "Trainable params: 349,489\n",
      "Non-trainable params: 2,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
