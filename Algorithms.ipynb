{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place helper functions on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_of_k_encoding(cols, df):\n",
    "    \"\"\" Categorial encoding of columns where datatype is categorical. \n",
    "        Input:    cols [list]\n",
    "                  df   [pd.DataFrame]\n",
    "        Output:   updated df\n",
    "    \"\"\"\n",
    "    assert type(cols)==list, \"Expecting a list.\"\n",
    "    for col in cols:\n",
    "        if col in df.columns.values: # Silently skip if not present\n",
    "            df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_titanic(file):\n",
    "    if os.path.isfile(file): \n",
    "        return pd.read_csv(file)\n",
    "    else:\n",
    "        print(sys.exc_info()[1])\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place derived classes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomStackedEnsembleClassifier():\n",
    "    \n",
    "    def __init__:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class RandomBlendingClassifier():\n",
    "    \n",
    "    def __init__:\n",
    "        pass\n",
    "    \n",
    "\n",
    "class TunedStackedEnsembleClassifier(n_classifier=5, \n",
    "                                     use_proba=False, ):\n",
    "    def __init__:\n",
    "        self.n_classifier == n_classifier # Choose number of clfs to draw from pool\n",
    "        self.use_proba = use_proba # Use probabilities\n",
    "        # Draw 'n_classifier' classifiers from space of available classifiers\n",
    "        n_sampled = 0; \n",
    "        while True:\n",
    "            # Implement choosing here.\n",
    "            if n_sampled==n_classifier: break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For now this cell contains all variables that govern program flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification = True\n",
    "# Init\n",
    "binary_classification = False; multiclass_classification = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.1 0.16.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(sklearn.__version__, \n",
    "      pd.__version__\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_titanic('data/train.csv')\n",
    "if data.shape[0]>0:\n",
    "    X_train, y_train = data.loc[:,:], np.array(data.pop('Survived'))\n",
    "    if len(np.unique(y_train))==2: \n",
    "        binary_classification = True\n",
    "    elif len(np.unique(y_train))>2:\n",
    "        multiclass_classification = True\n",
    "else:\n",
    "    sys.exit(sys.exc_info()[1])\n",
    "    \n",
    "uninformative = ['PassengerId', 'Ticket']\n",
    "for col in uninformative:\n",
    "    X_train.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "information = [('Pclass', 'category'), ('Name', str), ('Sex', 'category'), \n",
    "               ('Age', np.int8), ('SibSp', 'category'), ('Parch', 'category'), \n",
    "               ('Fare', np.float), ('Cabin', str), ('Embarked', 'category')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = one_of_k_encoding(['Sex', 'Embarked'], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 12), 891)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, len(y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to consider\n",
    "\n",
    "We have different types of learning:\n",
    "* Classification (binary, multiclass)\n",
    "* Regression\n",
    "* Unsupervised learning\n",
    "\n",
    "Some methods calculate probabilities, others do not (but output might be coerced into the correct form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start by importing supervised learning algorithms for classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier,  \\\n",
    "GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "BernoulliNB\n",
      "GaussianNB\n",
      "LinearDiscriminantAnalysis\n",
      "QuadraticDiscriminantAnalysis\n",
      "AdaBoostClassifier\n",
      "ExtraTreesClassifier\n",
      "DecisionTreeClassifier\n",
      "RandomForestClassifier\n",
      "GradientBoostingClassifier\n",
      "LinearSVC\n",
      "SVC\n",
      "KNeighborsClassifier\n",
      "MLPClassifier\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LogisticRegression(), \n",
    "               BernoulliNB(),\n",
    "               GaussianNB(),\n",
    "               LinearDiscriminantAnalysis(), \n",
    "               QuadraticDiscriminantAnalysis(), \n",
    "               AdaBoostClassifier(), \n",
    "               ExtraTreesClassifier(),\n",
    "               DecisionTreeClassifier(),\n",
    "               RandomForestClassifier(),\n",
    "               GradientBoostingClassifier(),\n",
    "               LinearSVC(),\n",
    "               SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "               KNeighborsClassifier(),\n",
    "               MLPClassifier(),\n",
    "]\n",
    "\n",
    "for clf in classifiers:\n",
    "    ##clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    print(name)  \n",
    "    \n",
    "# To do:\n",
    "# * Plot accuracy (or some other comparative measure) as a comparative bar chart\n",
    "# * Predict out-of-fold and compure pearson correlation between different classifier predictions:\n",
    "#   p(x,y) = cov(x,y)/sigma_x/sigma_y\n",
    "\n",
    "# * Choose an ensemble consisting of the N least correlated classifiers (best effect on overall performance)\n",
    "# * try different methods of ensembling: boosting, bagging, model stacking/blending\n",
    "#   See this post: https://mlwave.com/kaggle-ensembling-guide/\n",
    "#\n",
    "# * Consider model compression (Caruana et al paper): NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important points to remember:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], or standardize it to have mean 0 and variance 1. Note that you must apply the same scaling to the test set for meaningful results. You can use StandardScaler for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to train a single algorithm (perhaps one of the most expensive to train, such as SVM) on the full dataset. If this takes too long then we start by down-sampling the data, until we have something that is manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
