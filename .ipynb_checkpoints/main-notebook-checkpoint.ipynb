{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils; reload(utils)\n",
    "import class_handler as classes; reload(classes)\n",
    "import os\n",
    "import sys; sys.path.append(os.getcwd()+'/src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "x, y = load_breast_cancer(return_X_y=True)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (455,) (114, 30) (114,)\n"
     ]
    }
   ],
   "source": [
    "# Lets split into train and test\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base class for algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'does_regression': False, 'does_classification': True, 'does_multiclass': True, 'predict_probas': True}\n"
     ]
    }
   ],
   "source": [
    "import adaboost; reload(adaboost)\n",
    "from adaboost import MetaAdaBoostClassifierAlgorithm\n",
    "ada = MetaAdaBoostClassifierAlgorithm(random_state=0, base_estimator='logreg')\n",
    "print(ada.get_info())\n",
    "ada.cv_param_dist = ada._param_dist_dict()\n",
    "print(ada.cv_param_dist)\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_dist = ada.cv_param_dist\n",
    "estimator = ada.estimator\n",
    "\n",
    "# IT SEEMS THAT THE LOGISTIC REGRESSION CLASSIFIER TENDS TO OVERFIT...SHOULD LOWER n_iter IF USING THAT ALGO.\n",
    "grid_search = RandomizedSearchCV(estimator, param_distributions=param_dist, n_iter=1, scoring='neg_log_loss',\n",
    "                       cv=10, n_jobs=-1, verbose=0, error_score=0, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best mean score: %.4f\" % (grid_search.best_score_))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy on test set: %.4f\" % accuracy_score(y_test, grid_search.best_estimator_.predict(X_test))) \n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with nearest neighbors algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'does_regression': False, 'does_classification': True, 'does_multiclass': True, 'predict_probas': True}\n",
      "<class 'sklearn.model_selection._search.ParameterGrid'>\n"
     ]
    }
   ],
   "source": [
    "import nearest_neighbors; reload(nearest_neighbors)\n",
    "from nearest_neighbors import MetaKNearestNeighborClassifierAlgorithm\n",
    "knn = MetaKNearestNeighborClassifierAlgorithm()\n",
    "print(knn.get_info())\n",
    "knn.cv_param_dist = knn._param_dist_dict()\n",
    "print(type(knn.cv_param_dist))\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "param_dist = knn.cv_param_dist\n",
    "estimator = knn.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'leaf_size': [15, 30, 45],\n",
      "  'metric': ['minkowski'],\n",
      "  'p': [1, 2],\n",
      "  'weights': ['uniform', 'distance']},\n",
      " {'leaf_size': [15, 30, 45],\n",
      "  'metric': ['chebyshev'],\n",
      "  'weights': ['uniform', 'distance']}]\n",
      "number of grids = 2\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(param_dist.param_grid)\n",
    "print(\"number of grids = %i\" % len(param_dist.param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best mean score: 0.9341\n",
      "Accuracy on test set: 0.9474\n",
      "Best mean score: 0.9187\n",
      "Accuracy on test set: 0.9474\n",
      "[(0.93406593406593408, KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=1,\n",
      "           weights='uniform')), (0.91868131868131864, KNeighborsClassifier(algorithm='auto', leaf_size=45, metric='chebyshev',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='distance'))]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for grid in param_dist.param_grid:\n",
    "    grid_search = RandomizedSearchCV(estimator, param_distributions=grid, n_iter=2, scoring='accuracy',\n",
    "                           cv=10, n_jobs=-1, verbose=0, error_score=0, return_train_score=True)\n",
    "    #grid_search = GridSearchCV(estimator, param_grid=param_dist.param_grid, scoring='accuracy',\n",
    "    #                       cv=10, n_jobs=-1, verbose=0, error_score=0, return_train_score=True)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best mean score: %.4f\" % (grid_search.best_score_))\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(\"Accuracy on test set: %.4f\" % accuracy_score(y_test, grid_search.best_estimator_.predict(X_test))) \n",
    "    results.append((grid_search.best_score_, grid_search.best_estimator_))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import classifiers\n",
    "clfs = classes.Classifiers(verbose=0, method='complete', num_clf=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting and tuning of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way of optimizing the hyper parameters of each selected algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular fitting (just train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the basic building block: \"fit_classifiers\" loops over each algorithm and trains on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit classifiers on data\n",
    "clfs.fit_classifiers(X_train,y_train,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyper parameters using cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring options:\n",
    "* ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_median_absolute_error', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete and categorical variables (using scipy.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_scorer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "scorer = make_scorer(log_loss, greater_is_better=False)\n",
    "scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def neg_log_loss(y_true, y_pred):\n",
    "    return -1.0 * log_loss(y_true, y_pred)\n",
    "scorer = make_scorer(neg_log_loss)\n",
    "scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [1, 2, 3, 8, 12, None],\n",
    "              \"max_features\": sp_randint(2, 15),\n",
    "              \"min_samples_split\": sp_randint(2, 15),\n",
    "              \"min_samples_leaf\": sp_randint(2, 15),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"n_estimators\": [10, 100, 500]} \n",
    "estimator = RandomForestClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator, param_distributions=param_dist, n_iter=10, scoring=scorer,\n",
    "                       cv=10, n_jobs=-1, verbose=0, error_score=0, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "#pd.DataFrame(grid_search.cv_results_).head()\n",
    "print(\"Best mean score: %.4f\" % (grid_search.best_score_))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy on test set: %.4f\" % accuracy_score(y_test, grid_search.best_estimator_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous variable (using scipy.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, gamma, lognorm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "param_dist = {\"C\": uniform(loc=0., scale=200.),\n",
    "              \"fit_intercept\": [True, False],\n",
    "              \"penalty\": ['l1', 'l2'],\n",
    "              \"max_iter\": [50, 100, 150]}\n",
    "estimator = LogisticRegression()\n",
    "grid_search = RandomizedSearchCV(estimator, param_distributions=param_dist, n_iter=200, scoring='accuracy',\n",
    "                       cv=10, n_jobs=-1, verbose=0, error_score=0, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best mean score: %.4f\" % (grid_search.best_score_))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict on data (returns a list of (name, prediction) tuples for each classifier in repository)\n",
    "preds = clfs.predict_classifiers(X_train)\n",
    "clfs.verbose = 1 # Report progress if =1, else be quiet if =0.\n",
    "# How well are we doing?\n",
    "scores = clfs.classifier_performance(preds, y_train, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = clfs.predict_classifiers(X_test)\n",
    "clfs.verbose = 1 # Report progress if =1, else be quiet if =0.\n",
    "# How well are we doing?\n",
    "scores = clfs.classifier_performance(preds, y_test, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an instance \"correlation checking\" classes\n",
    "import class_handler as classes; reload(classes)\n",
    "check = classes.CheckClassifierCorrelation(prediction_type='c_binary')\n",
    "# Get names and correlation matrix\n",
    "names_, corr_ = check.compute_correlation_matrix(preds)\n",
    "# Plot correlation matrix (output depends on if plotting inline or not)\n",
    "fig = check.plot_correlation_matrix(names_, corr_, fig_size=(16,10), rot=20, font_scale=1.1, file=os.getcwd()+\"/corr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
